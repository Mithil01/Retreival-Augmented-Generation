{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain tiktoken pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTa8iY73t8qR",
        "outputId": "45716cb0-08e6-49d3-a830-f004f70b68cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-4.1.1-py3-none-any.whl (216 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.2/216.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.8)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.79)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.6.2)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (3.0.0)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone-client\n",
            "Successfully installed pinecone-client-4.1.1 pinecone-plugin-interface-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2YmD49kuoP0",
        "outputId": "77ff653e-3164-4397-967c-e7818550dc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.5)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.8)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.79)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain_community) (2.7.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain_community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain_community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.5 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypdf faiss-cpu openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4FYue3Xu622",
        "outputId": "54aaf7c0-80ad-45ac-fd65-098fb0ffdeb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jbuho8WtmWW",
        "outputId": "54665576-a4b4-45f6-8ec0-91689d5ef7cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Springer Series in Statistics\\nTrevor Hastie\\nRobert TibshiraniJerome FriedmanSpringer Series in Statistics\\nThe Elements of\\nStatistical Learning\\nData Mining, Inference, and Prediction\\nThe Elements of Statistical LearningDuring the past decade there has been an explosion in computation and information tech-', metadata={'source': 'stats_learning.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "file_path = 'stats_learning.pdf'\n",
        "\n",
        "loader = PyPDFLoader(file_path=file_path)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=0\n",
        ")\n",
        "\n",
        "data = loader.load_and_split(text_splitter=text_splitter)\n",
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBaYv7jpw9Hl",
        "outputId": "a80622bc-21fd-4738-849e-3120544bc6a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "data_0 = embeddings.embed_query(data[0].page_content)\n",
        "len(data_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJdrcRpgvHjC",
        "outputId": "fa3675ac-028b-456b-9c7c-6f5ad386b37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "vector_store = FAISS.from_documents(data, embeddings)"
      ],
      "metadata": {
        "id": "NMjWXNvQxxiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.similarity_search_with_relevance_scores(\"What is Random Forest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SauICKFyyLSK",
        "outputId": "6971da8e-9391-4a7f-91df-26b195e5c541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(page_content='590 15. Random Forests\\nRandom forests are popular. Leo Breiman’s1collaborator Adele Cutler\\nmaintains a random forest website2where the software is freely available,\\nwithmorethan3000downloadsreportedby2002.Thereisa randomForest\\npackage in R, maintained by Andy Liaw, available from the CRANwebsite.\\nThe authors make grand claims about the success of random for ests:\\n“most accurate,” “most interpretable,” and the like. In our experience ran-', metadata={'source': 'stats_learning.pdf', 'page': 608}),\n",
              "  0.7869172507528058),\n",
              " (Document(page_content='On many problems the performance of random forests is very si milar to\\nboosting,andtheyaresimplertotrainandtune.Asaconsequ ence,random\\nforests are popular, and are implemented in a variety of pack ages.\\n15.2 Deﬁnition of Random Forests\\nThe essential idea in bagging (Section 8.7) is to average man y noisy but\\napproximately unbiased models, and hence reduce the varian ce. Trees are\\nideal candidates for bagging, since they can capture comple x interaction', metadata={'source': 'stats_learning.pdf', 'page': 605}),\n",
              "  0.7811814018452612),\n",
              " (Document(page_content='602 15. Random Forests\\nRandom Forest Classifier\\no\\noooo\\nooo\\noo\\no\\noo\\noo\\nooo\\noo\\nooo\\noo\\noo\\no\\noo\\no\\noooo\\noo\\no\\noo\\noo\\nooo\\noo\\no\\nooo\\no\\noo\\noo\\no\\nooo\\noo\\no\\no\\noo\\no\\noo\\nooooo\\no\\noo\\no oo\\noo\\nooo\\noo\\noo\\noo\\noo\\noo\\nooo\\no\\nooooo\\noooo\\nooo\\noo\\nooo\\noo\\no\\noo\\no\\nooo\\noo ooo\\noo\\nooooo\\noo\\noo\\noo\\nooo\\nooooooo\\noo oooo\\noo\\noo\\noooo\\no\\noo\\noo\\nooooo\\nooo\\no\\no\\nooo\\noooooo\\noo\\no\\noo\\nooo\\no\\nTraining Error: 0.000\\nTest Error:       0.238\\nBayes Error:    0.2103−Nearest Neighbors\\no\\noooo\\nooo\\noo\\no\\noo\\noo\\nooo\\noo\\nooo\\noo\\noo\\no\\noo\\no\\noooo\\noo\\no\\noo\\noo\\nooo\\noo\\no\\nooo\\no', metadata={'source': 'stats_learning.pdf', 'page': 620}),\n",
              "  0.7775688900922713),\n",
              " (Document(page_content='15.2 Deﬁnition of Random Forests 589\\nBefore each split, select m≤pof the input variables at random\\nas candidates for splitting.\\nTypically values for mare√por even as low as 1.\\nAfterBsuchtrees{T(x;Θb)}B\\n1aregrown,therandomforest(regression)\\npredictor is\\nˆfB\\nrf(x) =1\\nBB∑\\nb=1T(x;Θb). (15.2)\\nAsinSection10.9(page356),Θ bcharacterizesthe bthrandomforesttreein\\nterms of split variables, cutpoints at each node, and termin al-node values.', metadata={'source': 'stats_learning.pdf', 'page': 607}),\n",
              "  0.763704136365582)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRkCB8ujR40V",
        "outputId": "ff66b424-c117-4fd9-e453-fe58e8d16160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.8)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.79)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxUI8o_dVyhg",
        "outputId": "eea72661-dfe6-4dac-d1a9-819986989649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement python (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for python\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "\n",
        "retriever = vector_store.as_retriever()\n",
        "retriever.search_kwargs['fetch_k'] = 10\n",
        "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
        "retriever.search_kwargs['k'] = 5\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "chain.run(\"what is Random Forest?\", callbacks=[StdOutCallbackHandler()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WlFJNZM8ybJD",
        "outputId": "15732760-9749-4e34-9e8d-f03deee34cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "590 15. Random Forests\n",
            "Random forests are popular. Leo Breiman’s1collaborator Adele Cutler\n",
            "maintains a random forest website2where the software is freely available,\n",
            "withmorethan3000downloadsreportedby2002.Thereisa randomForest\n",
            "package in R, maintained by Andy Liaw, available from the CRANwebsite.\n",
            "The authors make grand claims about the success of random for ests:\n",
            "“most accurate,” “most interpretable,” and the like. In our experience ran-\n",
            "\n",
            "On many problems the performance of random forests is very si milar to\n",
            "boosting,andtheyaresimplertotrainandtune.Asaconsequ ence,random\n",
            "forests are popular, and are implemented in a variety of pack ages.\n",
            "15.2 Deﬁnition of Random Forests\n",
            "The essential idea in bagging (Section 8.7) is to average man y noisy but\n",
            "approximately unbiased models, and hence reduce the varian ce. Trees are\n",
            "ideal candidates for bagging, since they can capture comple x interaction\n",
            "\n",
            "602 15. Random Forests\n",
            "Random Forest Classifier\n",
            "o\n",
            "oooo\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "o\n",
            "oooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "ooo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "o\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "o\n",
            "oo\n",
            "o\n",
            "oo\n",
            "ooooo\n",
            "o\n",
            "oo\n",
            "o oo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "oo\n",
            "oo\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "o\n",
            "ooooo\n",
            "oooo\n",
            "ooo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "o\n",
            "ooo\n",
            "oo ooo\n",
            "oo\n",
            "ooooo\n",
            "oo\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "ooooooo\n",
            "oo oooo\n",
            "oo\n",
            "oo\n",
            "oooo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "ooooo\n",
            "ooo\n",
            "o\n",
            "o\n",
            "ooo\n",
            "oooooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "ooo\n",
            "o\n",
            "Training Error: 0.000\n",
            "Test Error:       0.238\n",
            "Bayes Error:    0.2103−Nearest Neighbors\n",
            "o\n",
            "oooo\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "o\n",
            "oooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "ooo\n",
            "o\n",
            "\n",
            "15.2 Deﬁnition of Random Forests 589\n",
            "Before each split, select m≤pof the input variables at random\n",
            "as candidates for splitting.\n",
            "Typically values for mare√por even as low as 1.\n",
            "AfterBsuchtrees{T(x;Θb)}B\n",
            "1aregrown,therandomforest(regression)\n",
            "predictor is\n",
            "ˆfB\n",
            "rf(x) =1\n",
            "BB∑\n",
            "b=1T(x;Θb). (15.2)\n",
            "AsinSection10.9(page356),Θ bcharacterizesthe bthrandomforesttreein\n",
            "terms of split variables, cutpoints at each node, and termin al-node values.\n",
            "\n",
            "594 15. Random Forests\n",
            "!$removefreeCAPAVEyourCAPMAXhpCAPTOTmoneyouryougeorge000eduhplbusiness1999internet(willallemailrereceiveovermail;650meetinglabsorderaddresspmpeoplemake#creditfontdatatechnology85[labtelnetreportoriginalprojectconferencedirect415857addresses3dcspartstableGini\n",
            "0 20 40 60 80 100\n",
            "Human: what is Random Forest?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Random Forest is a popular machine learning algorithm that involves creating multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. It is known for its accuracy, interpretability, and simplicity in training and tuning compared to other methods like boosting. The algorithm involves selecting a random subset of input variables before each split and then averaging the predictions of multiple trees to make the final prediction.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuhahkAOnkJe",
        "outputId": "35a03976-b883-4677-c75e-b732d8528a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (0.2.8)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (1.25.2)\n",
            "Collecting pinecone-client<4.0.0,>=3.2.2 (from langchain_pinecone)\n",
            "  Downloading pinecone_client-3.2.2-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.9/215.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (0.1.79)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.7.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (8.3.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (2024.6.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (2.0.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.7)\n",
            "Installing collected packages: pinecone-client, langchain_pinecone\n",
            "  Attempting uninstall: pinecone-client\n",
            "    Found existing installation: pinecone-client 4.1.1\n",
            "    Uninstalling pinecone-client-4.1.1:\n",
            "      Successfully uninstalled pinecone-client-4.1.1\n",
            "Successfully installed langchain_pinecone-0.1.1 pinecone-client-3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"PINECONE_API_KEY\"] = getpass.getpass()\n",
        "os.environ[\"PINECONE_API_ENV\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygwmONswWKbs",
        "outputId": "59e6cd12-7eee-4728-b135-5e333994d391"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n",
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "index_name = \"ragapplication\"\n",
        "\n",
        "docsearch = PineconeVectorStore.from_documents(data, embeddings, index_name=index_name)\n"
      ],
      "metadata": {
        "id": "PWBikw2lYN6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_chain = RetrievalQA.from_chain_type(llm = llm, retriever = docsearch.as_retriever(),verbose = True )\n",
        "chain.run(\"what is Random Forest?\", callbacks=[StdOutCallbackHandler()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ynPlQN8CmRc7",
        "outputId": "e64e875a-f5e4-4886-d708-f1fa6262503d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "590 15. Random Forests\n",
            "Random forests are popular. Leo Breiman’s1collaborator Adele Cutler\n",
            "maintains a random forest website2where the software is freely available,\n",
            "withmorethan3000downloadsreportedby2002.Thereisa randomForest\n",
            "package in R, maintained by Andy Liaw, available from the CRANwebsite.\n",
            "The authors make grand claims about the success of random for ests:\n",
            "“most accurate,” “most interpretable,” and the like. In our experience ran-\n",
            "\n",
            "On many problems the performance of random forests is very si milar to\n",
            "boosting,andtheyaresimplertotrainandtune.Asaconsequ ence,random\n",
            "forests are popular, and are implemented in a variety of pack ages.\n",
            "15.2 Deﬁnition of Random Forests\n",
            "The essential idea in bagging (Section 8.7) is to average man y noisy but\n",
            "approximately unbiased models, and hence reduce the varian ce. Trees are\n",
            "ideal candidates for bagging, since they can capture comple x interaction\n",
            "\n",
            "602 15. Random Forests\n",
            "Random Forest Classifier\n",
            "o\n",
            "oooo\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "o\n",
            "oooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "ooo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "o\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "o\n",
            "oo\n",
            "o\n",
            "oo\n",
            "ooooo\n",
            "o\n",
            "oo\n",
            "o oo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "oo\n",
            "oo\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "o\n",
            "ooooo\n",
            "oooo\n",
            "ooo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "o\n",
            "ooo\n",
            "oo ooo\n",
            "oo\n",
            "ooooo\n",
            "oo\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "ooooooo\n",
            "oo oooo\n",
            "oo\n",
            "oo\n",
            "oooo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "ooooo\n",
            "ooo\n",
            "o\n",
            "o\n",
            "ooo\n",
            "oooooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "ooo\n",
            "o\n",
            "Training Error: 0.000\n",
            "Test Error:       0.238\n",
            "Bayes Error:    0.2103−Nearest Neighbors\n",
            "o\n",
            "oooo\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "o\n",
            "oooo\n",
            "oo\n",
            "o\n",
            "oo\n",
            "oo\n",
            "ooo\n",
            "oo\n",
            "o\n",
            "ooo\n",
            "o\n",
            "\n",
            "15.2 Deﬁnition of Random Forests 589\n",
            "Before each split, select m≤pof the input variables at random\n",
            "as candidates for splitting.\n",
            "Typically values for mare√por even as low as 1.\n",
            "AfterBsuchtrees{T(x;Θb)}B\n",
            "1aregrown,therandomforest(regression)\n",
            "predictor is\n",
            "ˆfB\n",
            "rf(x) =1\n",
            "BB∑\n",
            "b=1T(x;Θb). (15.2)\n",
            "AsinSection10.9(page356),Θ bcharacterizesthe bthrandomforesttreein\n",
            "terms of split variables, cutpoints at each node, and termin al-node values.\n",
            "\n",
            "594 15. Random Forests\n",
            "!$removefreeCAPAVEyourCAPMAXhpCAPTOTmoneyouryougeorge000eduhplbusiness1999internet(willallemailrereceiveovermail;650meetinglabsorderaddresspmpeoplemake#creditfontdatatechnology85[labtelnetreportoriginalprojectconferencedirect415857addresses3dcspartstableGini\n",
            "0 20 40 60 80 100\n",
            "Human: what is Random Forest?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Random Forest is a popular machine learning algorithm that involves creating multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. It is known for its accuracy, interpretability, and simplicity in training and tuning compared to other methods like boosting. The algorithm randomly selects a subset of input variables before each split and builds multiple trees to make predictions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "News-api"
      ],
      "metadata": {
        "id": "0XZ5lT42syS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install newsapi-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgfLcGfds0BQ",
        "outputId": "abc46b72-34e5-4bcc-e47a-083c0d7ecf64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newsapi-python\n",
            "  Downloading newsapi_python-0.2.7-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.10/dist-packages (from newsapi-python) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2024.6.2)\n",
            "Installing collected packages: newsapi-python\n",
            "Successfully installed newsapi-python-0.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"NEWS_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztr-tzeFs8WC",
        "outputId": "757f2472-a822-4a0e-d281-70af472f509d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date, timedelta\n",
        "from newsapi import NewsApiClient\n",
        "\n",
        "NEWS_API_KEY = 'e1d6c26d70894006bf85481154fbff04'\n",
        "newsapi = NewsApiClient(api_key=NEWS_API_KEY)\n",
        "\n",
        "today = date.today()\n",
        "last_week = today - timedelta(days=5)\n",
        "\n",
        "latest_news = newsapi.get_everything(\n",
        "    q='Machine Learning',\n",
        "    from_param=last_week.strftime(\"%Y-%m-%d\"),\n",
        "    to=today.strftime(\"%Y-%m-%d\"),\n",
        "    sort_by='relevancy',\n",
        "    language='en'\n",
        ")"
      ],
      "metadata": {
        "id": "K-H2uL2Ws2SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latest_news['articles'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUOTGBGwvoxV",
        "outputId": "6e487857-d6d7-4546-c951-37158a623978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': {'id': None, 'name': 'Slashdot.org'},\n",
              " 'author': 'EditorDavid',\n",
              " 'title': 'AI Researcher Warns Data Science Could Face a Reproducibility Crisis',\n",
              " 'description': 'Long-time Slashdot reader theodp shared this warning from a long-time AI researcher arguing that data science \"is due\" for a reckoning over whether results can be reproduced. \"Few technological revolutions came with such a low barrier of entry as Machine Lear…',\n",
              " 'url': 'https://slashdot.org/story/24/06/16/0131202/ai-researcher-warns-data-science-could-face-a-reproducibility-crisis',\n",
              " 'urlToImage': 'https://a.fsdn.com/sd/topics/ai_64.png',\n",
              " 'publishedAt': '2024-06-17T00:16:00Z',\n",
              " 'content': 'Unlike Machine Learning, Data Science is not an academic discipline, with its own set of algorithms and methods... There is an immense diversity, but also disparities in skill, expertise, and knowled… [+1811 chars]'}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "new_docs = [\n",
        "    Document(\n",
        "        page_content = \"\\n\\n\".join([str(news.get('title', ' ')),str(news.get('description', ' '))]),\n",
        "        metadata = {\"source\" : news['url'],}\n",
        "            ) for news in latest_news['articles']\n",
        "]\n",
        "\n",
        "new_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1ahFsAMt8lR",
        "outputId": "c07133d0-521e-44cf-eea9-c6a8176accb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='AI Researcher Warns Data Science Could Face a Reproducibility Crisis\\n\\nLong-time Slashdot reader theodp shared this warning from a long-time AI researcher arguing that data science \"is due\" for a reckoning over whether results can be reproduced. \"Few technological revolutions came with such a low barrier of entry as Machine Lear…', metadata={'source': 'https://slashdot.org/story/24/06/16/0131202/ai-researcher-warns-data-science-could-face-a-reproducibility-crisis'})"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_qa_with_sources_chain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "qa_chain = create_qa_with_sources_chain(llm)\n",
        "\n",
        "doc_prompt = PromptTemplate(\n",
        "    template=\"Content: {page_content}\\nSource: {source}\",\n",
        "    input_variables=[\"page_content\", \"source\"],\n",
        ")\n",
        "\n",
        "final_qa_chain = StuffDocumentsChain(\n",
        "    llm_chain=qa_chain,\n",
        "    document_variable_name=\"context\",\n",
        "    document_prompt=doc_prompt,\n",
        ")\n",
        "\n",
        "news_search = PineconeVectorStore.from_documents(new_docs, embeddings, index_name=index_name)\n",
        "\n",
        "news_chain = RetrievalQA(retriever = news_search.as_retriever(), combine_documents_chain=final_qa_chain)\n",
        "news_chain.run(\"What is the most important news about artificial intelligence from last week?\", callbacks=[StdOutCallbackHandler()])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "E1se6DjO0IW0",
        "outputId": "5854f5d3-05c3-4a0e-e6f0-e6fdec775c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a world class algorithm to answer questions in a specific format.\n",
            "Human: Answer question using the following context\n",
            "Human: Content: Quantum AI And Cognitive Robotics: The Future Of Intelligent Machines\n",
            "\n",
            "Quantum AI represents a revolutionary leap in computational power and efficiency.\n",
            "Source: https://www.forbes.com/sites/forbestechcouncil/2024/06/14/quantum-ai-and-cognitive-robotics-the-future-of-intelligent-machines/\n",
            "\n",
            "Content: Quantum AI And Cognitive Robotics: The Future Of Intelligent Machines\n",
            "\n",
            "Quantum AI represents a revolutionary leap in computational power and efficiency.\n",
            "Source: https://www.forbes.com/sites/forbestechcouncil/2024/06/14/quantum-ai-and-cognitive-robotics-the-future-of-intelligent-machines/\n",
            "\n",
            "Content: Quantum AI And Cognitive Robotics: The Future Of Intelligent Machines\n",
            "\n",
            "Quantum AI represents a revolutionary leap in computational power and efficiency.\n",
            "Source: https://www.forbes.com/sites/forbestechcouncil/2024/06/14/quantum-ai-and-cognitive-robotics-the-future-of-intelligent-machines/\n",
            "\n",
            "Content: Quantum AI And Cognitive Robotics: The Future Of Intelligent Machines\n",
            "\n",
            "Quantum AI represents a revolutionary leap in computational power and efficiency.\n",
            "Source: https://www.forbes.com/sites/forbestechcouncil/2024/06/14/quantum-ai-and-cognitive-robotics-the-future-of-intelligent-machines/\n",
            "Human: Question: What is the most important news about artificial intelligence from last week?\n",
            "Human: Tips: Make sure to answer in the correct format\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"answer\": \"The most important news about artificial intelligence from last week is the revolutionary leap in computational power and efficiency brought by Quantum AI. This advancement signifies a significant development in the field of artificial intelligence and cognitive robotics.\",\\n  \"sources\": [\\n    \"https://www.forbes.com/sites/forbestechcouncil/2024/06/14/quantum-ai-and-cognitive-robotics-the-future-of-intelligent-machines/\"\\n  ]\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install GitPython --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaUPvz0o8k2U",
        "outputId": "1dcb3206-2b78-4767-e18d-46de1575fb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import GitLoader\n",
        "\n",
        "\n",
        "\n",
        "loader = GitLoader(\n",
        "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
        "    repo_path=\"./data/repo/\",\n",
        "    file_filter=lambda file_path: file_path.endswith(\".py\"),\n",
        "    branch=\"master\",\n",
        ")\n",
        "\n",
        "documents = loader.load()\n"
      ],
      "metadata": {
        "id": "l2v1Aheo8nXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resplit the documents in Python language\n",
        "\n",
        "from langchain.text_splitter import Language\n",
        "\n",
        "python_code_text_splitter = RecursiveCharacterTextSplitter.from_language(Language.PYTHON, chunk_size=500,chunk_overlap=150)\n",
        "\n",
        "# Filter out documents containing the special token before splitting\n",
        "filtered_documents = [doc for doc in documents if '<|endoftext|>' not in doc.page_content]\n",
        "python_docs = python_code_text_splitter.split_documents(filtered_documents)\n"
      ],
      "metadata": {
        "id": "0FvkNT6E9FLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = FAISS.from_documents(python_docs, embeddings)\n",
        "retreiver = index.as_retriever()\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm, chain_type=\"stuff\", retriever=retreiver)"
      ],
      "metadata": {
        "id": "lPYpNBSw-vSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is a stuff chain?\"\n",
        "\n",
        "qa.run(query, callbacks=[StdOutCallbackHandler()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "ukFmsSQn-tjE",
        "outputId": "ee4727e2-b0f4-4e1b-dfd5-ea5c82aeb944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
            "from langchain.chains.llm import LLMChain\n",
            "from langchain.chains.question_answering import (\n",
            "    map_reduce_prompt,\n",
            "    refine_prompts,\n",
            "    stuff_prompt,\n",
            ")\n",
            "from langchain.chains.question_answering.map_rerank_prompt import (\n",
            "    PROMPT as MAP_RERANK_PROMPT,\n",
            ")\n",
            "\n",
            "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
            "from langchain.chains.llm import LLMChain\n",
            "from langchain.chains.summarize import map_reduce_prompt, refine_prompts, stuff_prompt\n",
            "\n",
            "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
            "from langchain.chains.qa_with_sources.base import BaseQAWithSourcesChain\n",
            "\n",
            "chain = prompt | fake_llm\n",
            "Human: What is a stuff chain?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A Stuff chain is a component in the Langchain library that is used for combining documents. It is used in conjunction with other chains like LLM (Large Language Model) for various natural language processing tasks such as question answering and summarization. The Stuff chain likely handles the processing and organization of textual data from multiple sources.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    }
  ]
}